{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.metrics import categorical_accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled.\n"
     ]
    }
   ],
   "source": [
    "# CUDA 를 이용한 GPU 가속\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Mac M1에서 Pytorch 를 이용할 때 GPU 연산 가속을 위한 MPS\n",
    "elif torch.torch.backends.mps.is_available():\n",
    "    device = torch.device('mps:0')\n",
    "\n",
    "    print(\"MPS enabled.\")\n",
    "\n",
    "# CPU 이용\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':8e-3,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':42\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "torch.manual_seed(CFG['SEED'])\n",
    "np.random.seed(CFG['SEED'])\n",
    "random.seed(CFG['SEED'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "# IRIS dataset 불러오기\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                  5.1               3.5                1.4               0.2   \n1                  4.9               3.0                1.4               0.2   \n2                  4.7               3.2                1.3               0.2   \n3                  4.6               3.1                1.5               0.2   \n4                  5.0               3.6                1.4               0.2   \n..                 ...               ...                ...               ...   \n145                6.7               3.0                5.2               2.3   \n146                6.3               2.5                5.0               1.9   \n147                6.5               3.0                5.2               2.0   \n148                6.2               3.4                5.4               2.3   \n149                5.9               3.0                5.1               1.8   \n\n     target  \n0       0.0  \n1       0.0  \n2       0.0  \n3       0.0  \n4       0.0  \n..      ...  \n145     2.0  \n146     2.0  \n147     2.0  \n148     2.0  \n149     2.0  \n\n[150 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%ㅑ\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0    50\n1.0    50\n2.0    50\nName: target, dtype: int64"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=CFG['SEED'])\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=CFG['SEED'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.features[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "val_dataset = CustomDataset(x_val, y_val)\n",
    "test_dataset = CustomDataset(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "class NeuralNetworkClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(NeuralNetworkClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim, 512)\n",
    "        self.hidden_layer1    = nn.Linear(512, 256)\n",
    "        self.hidden_layer2    = nn.Linear(256, 128)\n",
    "        self.hidden_layer3  = nn.Linear(128, 64)\n",
    "        self.output_layer   = nn.Linear(64,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.input_layer(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.hidden_layer1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.hidden_layer2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.hidden_layer3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        val_loss = []\n",
    "        preds, trues = [], []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                logit = model(inputs)\n",
    "                loss = criterion(logit, labels)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "                trues += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            _val_loss = np.mean(val_loss)\n",
    "\n",
    "        # _val_categorical_accuracy = np.mean(categorical_accuracy(trues, preds))\n",
    "        _val_accuracy = accuracy_score(trues, preds)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: \"\n",
    "              f\"Train Loss: {_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {_val_loss:.4f}, \"\n",
    "              f\"Val Accuracy: {_val_accuracy:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if _val_loss < best_val_loss:\n",
    "            best_val_loss = _val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    num_samples = len(test_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_accuracy = accuracy / num_samples * 100\n",
    "\n",
    "    print(f\"Test Accuracy: {avg_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.1033, Val Loss: 1.0821, Val Accuracy: 0.3000\n",
      "Epoch 2: Train Loss: 1.0603, Val Loss: 1.0393, Val Accuracy: 0.5667\n",
      "Epoch 3: Train Loss: 0.9898, Val Loss: 0.9948, Val Accuracy: 0.5667\n",
      "Epoch 4: Train Loss: 0.8825, Val Loss: 0.8631, Val Accuracy: 0.5667\n",
      "Epoch 5: Train Loss: 0.6794, Val Loss: 0.6324, Val Accuracy: 0.5667\n",
      "Epoch 6: Train Loss: 0.4894, Val Loss: 0.4776, Val Accuracy: 0.8667\n",
      "Epoch 7: Train Loss: 0.4107, Val Loss: 0.4477, Val Accuracy: 0.7000\n",
      "Epoch 8: Train Loss: 0.3289, Val Loss: 0.4197, Val Accuracy: 0.7333\n",
      "Epoch 9: Train Loss: 0.2446, Val Loss: 0.6397, Val Accuracy: 0.6000\n",
      "Epoch 10: Train Loss: 0.2136, Val Loss: 0.2865, Val Accuracy: 0.8667\n",
      "Epoch 11: Train Loss: 0.2576, Val Loss: 0.6028, Val Accuracy: 0.7333\n",
      "Epoch 12: Train Loss: 0.4211, Val Loss: 0.5837, Val Accuracy: 0.7333\n",
      "Epoch 13: Train Loss: 0.2865, Val Loss: 0.2027, Val Accuracy: 0.9333\n",
      "Epoch 14: Train Loss: 0.5163, Val Loss: 0.9919, Val Accuracy: 0.5667\n",
      "Epoch 15: Train Loss: 0.5363, Val Loss: 0.5422, Val Accuracy: 0.7333\n",
      "Epoch 16: Train Loss: 0.5161, Val Loss: 0.5052, Val Accuracy: 0.7000\n",
      "Epoch 17: Train Loss: 0.4135, Val Loss: 0.5531, Val Accuracy: 0.6000\n",
      "Epoch 18: Train Loss: 0.3748, Val Loss: 0.4460, Val Accuracy: 0.9000\n",
      "Epoch 19: Train Loss: 0.3303, Val Loss: 0.4328, Val Accuracy: 0.7333\n",
      "Epoch 20: Train Loss: 0.3034, Val Loss: 0.3037, Val Accuracy: 0.9333\n",
      "Epoch 21: Train Loss: 0.2051, Val Loss: 0.2619, Val Accuracy: 0.9000\n",
      "Epoch 22: Train Loss: 0.1465, Val Loss: 0.1914, Val Accuracy: 0.9333\n",
      "Epoch 23: Train Loss: 0.0953, Val Loss: 0.1712, Val Accuracy: 0.9333\n",
      "Epoch 24: Train Loss: 0.3020, Val Loss: 0.1475, Val Accuracy: 0.9333\n",
      "Epoch 25: Train Loss: 0.6621, Val Loss: 0.4941, Val Accuracy: 0.7667\n",
      "Epoch 26: Train Loss: 0.6229, Val Loss: 0.6095, Val Accuracy: 0.7000\n",
      "Epoch 27: Train Loss: 0.5389, Val Loss: 0.4607, Val Accuracy: 0.9000\n",
      "Epoch 28: Train Loss: 0.4302, Val Loss: 0.5256, Val Accuracy: 0.5667\n",
      "Epoch 29: Train Loss: 0.4008, Val Loss: 0.4403, Val Accuracy: 0.6333\n",
      "Epoch 30: Train Loss: 0.3650, Val Loss: 0.3903, Val Accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": "NeuralNetworkClassificationModel(\n  (input_layer): Linear(in_features=4, out_features=512, bias=True)\n  (hidden_layer1): Linear(in_features=512, out_features=256, bias=True)\n  (hidden_layer2): Linear(in_features=256, out_features=128, bias=True)\n  (hidden_layer3): Linear(in_features=128, out_features=64, bias=True)\n  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetworkClassificationModel(4, 3)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=CFG['LEARNING_RATE'], momentum=0.9)\n",
    "\n",
    "train(model, train_loader, val_loader, criterion, optimizer, CFG['EPOCHS'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader, criterion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
